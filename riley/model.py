# -*- coding: utf-8 -*-
"""model.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/16PGM9TCouSwwviKuDGwkwi_b9Pp-6T4J
"""

import torch
import torch.optim as optim
import torch.nn as nn
from pre_process import create_dataloaders
from model import RBFNetwork, initialize_rbf_centers

def train_model_full(model, train_loader, criterion, optimizer, device, num_epochs=20):
    print("Training on the full dataset...")
    for epoch in range(num_epochs):
        model.train()
        train_loss = 0.0
        for features, labels in train_loader:
            features = features.to(device)
            # Convert one-hot labels to class indices.
            labels = labels.argmax(dim=1).to(device)
            optimizer.zero_grad()
            outputs = model(features)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            train_loss += loss.item()
        avg_loss = train_loss / len(train_loader)
        print(f"Epoch {epoch+1}/{num_epochs} | Train Loss: {avg_loss:.4f}")

if __name__ == "__main__":
    # Create data loaders.
    train_dl, valid_dl, test_dl, full_train_loader = create_dataloaders()

    # Determine input dimensions and number of classes.
    sample_feature, sample_label = next(iter(train_dl))
    input_dim = sample_feature.numel() // sample_feature.shape[0]
    num_classes = sample_label.shape[1]

    # Set up device.
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"Using device: {device}")

    # Initialize the RBF network.
    model_full = RBFNetwork(input_dim=input_dim,
                            num_rbf_units=256,
                            num_classes=num_classes,
                            gamma=0.1,
                            hidden_dim=512,
                            dropout_prob=0.5).to(device)

    # Optionally initialize RBF centers using KMeans.
    initialize_rbf_centers(model_full, full_train_loader, device, num_samples=500)

    # Set up optimizer and loss function.
    optimizer_full = optim.Adam(model_full.parameters(), lr=0.001, weight_decay=1e-4)
    criterion = nn.CrossEntropyLoss()

    # Train the model.
    train_model_full(model_full, full_train_loader, criterion, optimizer_full, device, num_epochs=20)

    # Save the model.
    torch.save(model_full.state_dict(), "rbf_model.pth")
    print("Model training complete and saved as 'rbf_model.pth'.")